{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dynalign.experiments.paths import LP_EVALUATION_RESULTS, PREV_EXPERIMENTS_PATH\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Union, Tuple\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def get_dirs_from_path(path: Path, only_files_with_extension: str = \"\") -> List[Path]:\n",
    "    if only_files_with_extension:\n",
    "        return list(path.glob(f\"*{only_files_with_extension}\"))\n",
    "    else:\n",
    "        return [it for it in path.iterdir() if \".gitignore\" not in str(it)]\n",
    "\n",
    "\n",
    "DF_COLUMNS_TO_AGGREGATION = [\"run\", \"embeddings_aggregation\"]\n",
    "\n",
    "\n",
    "def aggregate_aligner_results_(\n",
    "    df: pd.DataFrame, metric_name: str, precision: float = 3\n",
    ") -> pd.DataFrame:\n",
    "    df_columns_to_aggregation = [*DF_COLUMNS_TO_AGGREGATION, metric_name]\n",
    "    df_columns_to_remove = set(df.columns).difference(set(df_columns_to_aggregation))\n",
    "    #     df = df[df.prediction_snapshot == df.prediction_snapshot.max()].copy()\n",
    "    snapshots_results = {}\n",
    "    for snapshot in df.prediction_snapshot.unique():\n",
    "        snapshot_df = df[\n",
    "            (df.prediction_snapshot == snapshot)\n",
    "            & (df.snapshot != df.prediction_snapshot)\n",
    "        ].copy()\n",
    "        snapshot_df = snapshot_df.drop(df_columns_to_remove, axis=1)\n",
    "        snapshot_df = (\n",
    "            snapshot_df.groupby(by=[\"embeddings_aggregation\"])\n",
    "            .agg((\"mean\", \"std\"))\n",
    "            .drop(\"run\", axis=1)\n",
    "        )\n",
    "\n",
    "        snapshot_df = snapshot_df.apply(\n",
    "            lambda x: (\n",
    "                round(x[metric_name][\"mean\"], precision),\n",
    "                round(x[metric_name][\"std\"], precision),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        snapshots_results[snapshot] = snapshot_df.to_dict()\n",
    "    return snapshots_results\n",
    "\n",
    "\n",
    "def aggreagte_all_results_last_snapshot(\n",
    "    paths: str, metric_name: str, precision: float = 3\n",
    "):\n",
    "    results = []\n",
    "    for method_results_path in paths:\n",
    "        method_name = method_results_path.name\n",
    "        method_ds_results_paths = get_dirs_from_path(\n",
    "            method_results_path, only_files_with_extension=\".pkl\"\n",
    "        )\n",
    "\n",
    "        for method_ds_results_path in method_ds_results_paths:\n",
    "            ds_name = method_ds_results_path.name.replace(\".pkl\", \"\")\n",
    "\n",
    "            alignment_snapshot = \"zero\"\n",
    "            if \"prev\" in str(method_ds_results_path):\n",
    "                alignment_snapshot = \"prev\"\n",
    "            elif \"full\" in str(method_ds_results_path):\n",
    "                alignment_snapshot = \"none\"\n",
    "\n",
    "            method_df = pd.read_pickle(method_ds_results_path)\n",
    "            for snapshot in method_df.prediction_snapshot.unique():\n",
    "                snapshot_df = method_df[\n",
    "                    (method_df.prediction_snapshot == snapshot)\n",
    "                    & (method_df.same_snapshot_prediction == False)\n",
    "                ].copy()\n",
    "\n",
    "                snapshot_df = snapshot_df[\n",
    "                    [\n",
    "                        \"run\",\n",
    "                        \"embeddings_aggregation\",\n",
    "                        metric_name,\n",
    "                    ]\n",
    "                ]\n",
    "\n",
    "                for _, row in snapshot_df.iterrows():\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"ds\": ds_name,\n",
    "                            \"method_name\": method_name,\n",
    "                            \"aggregation_method\": row[\"embeddings_aggregation\"],\n",
    "                            \"alignment_snapshot\": alignment_snapshot,\n",
    "                            metric_name: row[metric_name],\n",
    "                            \"snapshot\": snapshot,\n",
    "                            \"run\": row[\"run\"],\n",
    "                        }\n",
    "                    )\n",
    "    return results\n",
    "\n",
    "\n",
    "def convert_float_to_str(x: float) -> str:\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "def percentage_style(\n",
    "    x: Union[float, Tuple[float, float]]\n",
    ") -> Union[float, Tuple[float, float]]:\n",
    "    \"\"\"Percantage style fn.\"\"\"\n",
    "    if isinstance(x, float):\n",
    "        return round(x * 100, 2)\n",
    "    elif isinstance(x, tuple):\n",
    "        return round(x[0] * 100, 2), round(x[1] * 100, 2)\n",
    "    raise ValueError(\"X parsing error\")\n",
    "\n",
    "\n",
    "def highlight_max(x: pd.Series) -> List[str]:\n",
    "    values = [it[0] if it else 0 for it in x.values]\n",
    "    max_id = np.argmax(values)\n",
    "\n",
    "    output = []\n",
    "    for i in range(len(x)):\n",
    "        if i == max_id:\n",
    "            output.append(\"color:red\")\n",
    "        else:\n",
    "            output.append(\"\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_dirs_from_path(LP_EVALUATION_RESULTS)\n",
    "results = aggreagte_all_results_last_snapshot(paths, metric_name=\"auc\", precision=3)\n",
    "df = pd.DataFrame(results)\n",
    "df[\"method_name\"] = \"Node2Vec (snapshot)\"\n",
    "results = df.to_dict(orient=\"records\")\n",
    "\n",
    "prev_paths = get_dirs_from_path(PREV_EXPERIMENTS_PATH / \"evaluation\" / \"lp\")\n",
    "results.extend(\n",
    "    aggreagte_all_results_last_snapshot(prev_paths, metric_name=\"auc\", precision=3)\n",
    ")\n",
    "full_paths = get_dirs_from_path(Path(\"../data/evaluation_full/lp/\"))\n",
    "results.extend(\n",
    "    aggreagte_all_results_last_snapshot(full_paths, metric_name=\"auc\", precision=3)\n",
    ")\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098f51b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "@interact\n",
    "def plot_results(\n",
    "    dataset=results_df.ds.unique(),\n",
    "    aggregation_method=results_df.aggregation_method.unique(),\n",
    ") -> None:\n",
    "    alignment_df = results_df[\n",
    "        (results_df.ds == dataset)\n",
    "        & (results_df.aggregation_method == aggregation_method)\n",
    "        & (results_df.alignment_snapshot == \"prev\") \n",
    "        & (results_df.snapshot > 1)\n",
    "    ].sort_values(by=\"method_name\").copy()\n",
    "    \n",
    "    n2v_df = results_df[\n",
    "          (results_df.ds == dataset)\n",
    "        & (results_df.aggregation_method == \"last\")\n",
    "        & (results_df.method_name.str.contains(\"Node2Vec\")) \n",
    "        & (results_df.snapshot > 1)].copy()\n",
    "    \n",
    "    df = pd.concat([alignment_df, n2v_df], ignore_index=True)\n",
    "    fig = px.box(\n",
    "        data_frame=df,\n",
    "        x=\"snapshot\",\n",
    "        y=\"auc\",\n",
    "        color=\"method_name\"\n",
    "    )\n",
    "    fig.show()\n",
    "#     display(df)\n",
    "    \n",
    "    \n",
    "#     sub_df = df[(df.alignment_snapshot == \"prev\") & (df.aggregation_method == \"last\")].copy()\n",
    "#     display(sub_df.groupby([\"ds\", \"method_name\", \"snapshot\"]).agg([\"mean\", \"std\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938baf14",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb553b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\n",
    "    \"Node2Vec\",\n",
    "    \"Node2Vec (snapshot)\",\n",
    "    \"PosthocALL\",\n",
    "    \"PosthocEJ\",\n",
    "    \"PosthocTB\",\n",
    "    \"Node2VecAligned_L2_ALL\",\n",
    "    \"Node2VecAligned_L2_EJ\",\n",
    "    \"Node2VecAligned_L2_EJ_Weighted\",\n",
    "    \"Node2VecAligned_L2_TB\",\n",
    "    \"Node2VecAligned_L2_TB_Weighted\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839ee1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "markdown_str = ''\n",
    "best_aggregation_method = {}\n",
    "for idx, ds_results in results_df.groupby(by=\"ds\"):\n",
    "    ds_df = ds_results.copy()\n",
    "    display(idx)\n",
    "    ds_df.drop([\"ds\", \"alignment_snapshot\"], axis=1, inplace=True)\n",
    "    ds_df = ds_df[ds_df.snapshot == ds_df.snapshot.max()].drop([\"snapshot\"], axis=1)\n",
    "    ds_df.columns = [\"method_name\", \"aggregation_method\", \"auc\", \"run\"]\n",
    "    #     display(ds_df[\"method_name\"])\n",
    "    ds_df = (\n",
    "        ds_df.groupby(by=[\"method_name\", \"aggregation_method\"])\n",
    "        .aggregate([\"mean\", \"std\"])\n",
    "        .drop(\"run\", axis=1)\n",
    "        #\n",
    "    )\n",
    "    #     display(ds_df.fillna(0))\n",
    "    #     ds_df.drop([\"Node2Vec\", \"Node2Vec (snapshot)\"], inplace=True)\n",
    "    ds_df = (\n",
    "        ds_df.apply(\n",
    "            lambda x: (round(x[\"auc\"][\"mean\"], 3), round(x[\"auc\"][\"std\"], 3)),\n",
    "            axis=1,\n",
    "        )\n",
    "        .to_frame()\n",
    "        .reset_index()\n",
    "        .pivot(index=\"method_name\", columns=\"aggregation_method\", values=0)\n",
    "        .applymap(lambda x: (0.0, 0.0) if isinstance(x, float) else x)\n",
    "    )\n",
    "    best_aggregation_method[idx] = ds_df.applymap(lambda x: x[0]).max().idxmax()\n",
    "    display(ds_df.style.highlight_max())\n",
    "    markdown_str += (idx + \" \\n \\n \")\n",
    "    markdown_str +=(\n",
    "        ds_df.loc[\n",
    "            ds_df.max(axis=1).apply(lambda x: x[0]).sort_values(ascending=False).index\n",
    "        ].to_markdown() + \" \\n \\n\" \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5cf986",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_aggregation_method = {\n",
    "    \"Node2Vec\": \"last\",\n",
    "    \"Node2Vec (snapshot)\": \"last\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cc01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aggregation_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = defaultdict(dict)\n",
    "for idx, ds_results in results_df.groupby(by=\"ds\"):\n",
    "    ds_df = ds_results.copy()\n",
    "    ds_df.drop([\"ds\", \"alignment_snapshot\"], axis=1, inplace=True)\n",
    "    ds_df = ds_df[ds_df.snapshot == ds_df.snapshot.max()].drop([\"snapshot\"], axis=1)\n",
    "\n",
    "    for method_name, method_df in ds_df.groupby(by=\"method_name\"):\n",
    "        aggregation_method = (\n",
    "            best_aggregation_method[idx]\n",
    "            if not method_name in node2vec_aggregation_method.keys()\n",
    "            else node2vec_aggregation_method[method_name]\n",
    "        )\n",
    "        method_df = method_df[method_df.aggregation_method == aggregation_method]\n",
    "        assert len(method_df) == method_df.run.max() + 1\n",
    "        mean_auc = method_df['auc'].mean().round(3)\n",
    "        mean_std = method_df['auc'].std().round(3)\n",
    "        results_data[idx][method_name] = (mean_auc, mean_std)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_score_bold(x: pd.Series) -> List[str]:\n",
    "    max_id = np.argmax(x.values)\n",
    "\n",
    "    output = []\n",
    "    for i in range(len(x)):\n",
    "        if i == max_id:\n",
    "            out_str = f'$\\\\mathbf{{{convert_float_to_str(x[i][0]) + \" ± \" + convert_float_to_str(x[i][1])}}}'\n",
    "            out_str += \"$\"\n",
    "            output.append(out_str)\n",
    "\n",
    "        elif -1_000_000 < x[i][0] < 1_000_000:\n",
    "            out_str = f'${convert_float_to_str(x[i][0]) + \" ± \" + convert_float_to_str(x[i][1])}'\n",
    "            out_str += \"$\"\n",
    "            output.append(out_str)\n",
    "\n",
    "        else:\n",
    "            output.append(\"$\\\\times$\")\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results_data).loc[order]\n",
    "mean_rank = results.applymap(lambda x: x[0]).rank(ascending=False).mean(axis=1).round(2)\n",
    "# results = results.applymap(percentage_style)\n",
    "results = results.apply(get_top_score_bold)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb006a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = {\n",
    "    \"PosthocTB\": \"Posthoc-TB\",\n",
    "    \"PosthocEJ\": \"Posthoc-EJ\",\n",
    "    \"PosthocALL\": \"Posthoc-PA\",\n",
    "    \"Node2VecAligned_L2_ALL\": \"\\makecell[l]{Node2Vec \\\\\\\\ (Regularized, All)}\",\n",
    "    \"Node2VecAligned_L2_EJ\": \"\\makecell[l]{Node2Vec \\\\\\\\ (Regularized, EJ)}\",\n",
    "    \"Node2VecAligned_L2_EJ_Weighted\": \"\\makecell[l]{Node2Vec \\\\\\\\ (Regularized, \\\\\\\\ Weighted, EJ)}\",\n",
    "    \"Node2VecAligned_L2_TB\": \"\\makecell[l]{Node2Vec \\\\\\\\ (Regularized, TB)}\",\n",
    "    \"Node2VecAligned_L2_TB_Weighted\": \"\\makecell[l]{Node2Vec \\\\\\\\ (Regularized, \\\\\\\\ Weighted, TB)}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa47d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results_data).loc[order]\n",
    "mean_rank = results.applymap(lambda x: x[0]).rank(ascending=False).mean(axis=1).round(2)\n",
    "results = results.applymap(percentage_style)\n",
    "results = results.apply(get_top_score_bold)\n",
    "results[\"Mean rank\"] = [f'{it:.2f}' for it in mean_rank]\n",
    "results = results.loc[order].rename(MODEL_NAMES, axis=0)\n",
    "# results = results.sort_values(by=\"Mean rank\").rename(MODEL_NAMES, axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((\n",
    "    results.style.to_latex()\n",
    "    .replace(\"{llllll}\", \"{lrrrrr}\\n\\\\toprule\")\n",
    "    .replace(\"&  &  &  &  &  \\\\\\\\\", \"\")\n",
    "    .replace(\"NaN\", \"---\")\n",
    "    .replace(\"±\", r\"\\pm\")\n",
    "    .replace(r\"\\$\", \"$\")\n",
    "    .replace(\"textbackslash \", \"\")\n",
    "    .replace(\"\\{\", \"{\")\n",
    "    .replace(r\"\\}\", \"}\")\n",
    "    .replace(\"_\", \"\\_\")\n",
    "    .replace(\"}<KLEJ>\", \"\\\\textcolor{red}{*}}\")\n",
    "    .replace(\"mathbf\", \"mathbf\")\n",
    "    .replace(\"\\\\end{tabular}\", \"\\\\bottomrule \\n\\\\end{tabular}\")\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
