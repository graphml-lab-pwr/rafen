{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfd3fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from dynalign.experiments.paths import EMBEDDINGS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242689a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_metadata_paths(path):\n",
    "    models_paths = [it for it in EMBEDDINGS_PATH.iterdir() if it.is_dir()]\n",
    "    all_paths = []\n",
    "    for model_path in models_paths:\n",
    "        all_paths += [it for it in model_path.iterdir() if \"metadata\" in str(it)]\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def read_metadata(paths):\n",
    "    parsed_metadata = defaultdict(dict)\n",
    "    for path in tqdm(paths):\n",
    "        ds = path.name.replace(\"_metadata.pkl\", \"\")\n",
    "        model_name = path.parent.name\n",
    "        parsed_metadata[model_name][ds] = pd.read_pickle(path)\n",
    "\n",
    "    return parsed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5f17a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metadata_paths = get_all_metadata_paths(EMBEDDINGS_PATH)\n",
    "metadata = read_metadata(metadata_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811e0c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = list(metadata[list(metadata.keys())[0]].keys())\n",
    "models = list(metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9af4c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_epoch_time_log(metrics):\n",
    "    total_times_log = defaultdict(int)\n",
    "    for epoch_metrics in metrics.values():\n",
    "        for epoch_metric_key in epoch_metrics.keys():\n",
    "            total_times_log[f\"total_{epoch_metric_key}\"] += np.sum(\n",
    "                epoch_metrics[epoch_metric_key]\n",
    "            )\n",
    "    return total_times_log\n",
    "\n",
    "\n",
    "def get_snapshot_calculation_times(metrics):\n",
    "    out_metrics = {}\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        if k == \"epoch_time_log\":\n",
    "            continue\n",
    "\n",
    "        out_metrics[k] = np.sum(v)\n",
    "\n",
    "    out_metrics[\"computation_time\"] = np.sum(\n",
    "        [\n",
    "            v\n",
    "            for k, v in out_metrics.items()\n",
    "            if k in {\"training_step_time\", \"loss_backward_time\", \"optimizer_step_time\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return out_metrics\n",
    "\n",
    "\n",
    "def get_run_calculation_times(metrics, model_name):\n",
    "    out_metrics = defaultdict(int)\n",
    "    for snapshot_id, snapshot_metrics in enumerate(metrics):\n",
    "        if model_name == \"Node2Vec\" and snapshot_id == 0:\n",
    "            continue\n",
    "            \n",
    "        parsed_metrics = get_snapshot_calculation_times(\n",
    "            snapshot_metrics[\"enhanced_time_log\"]\n",
    "        )\n",
    "        for k, v in parsed_metrics.items():\n",
    "            out_metrics[k] += v\n",
    "        \n",
    "    \n",
    "        out_metrics[\"total_calculation_time\"] += snapshot_metrics[\"calculation_time\"]\n",
    "        \n",
    "\n",
    "    return out_metrics\n",
    "\n",
    "\n",
    "def get_calculation_times(metadata, model_name, dataset_name):\n",
    "    model_ds_metadata = metadata[model_name][dataset_name][\"metrics\"]\n",
    "    out_metrics = defaultdict(list)\n",
    "\n",
    "    for run_id, run in enumerate(model_ds_metadata):\n",
    "        run_metrics = get_run_calculation_times(\n",
    "            model_ds_metadata[run_id], model_name=model_name\n",
    "        )\n",
    "\n",
    "        for k, v in run_metrics.items():\n",
    "            out_metrics[k].append(v)\n",
    "\n",
    "    averaged_metrics = {\n",
    "        k: (np.mean(v).round(4), np.std(v).round(4)) for k, v in out_metrics.items()\n",
    "    }\n",
    "    return out_metrics, averaged_metrics\n",
    "\n",
    "\n",
    "# calculation_times_test = get_detailed_calculation_times(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b68de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for dataset in datasets:\n",
    "    dataset_times = {}\n",
    "\n",
    "    for model in models:\n",
    "        dataset_times[model] = get_calculation_times(\n",
    "            metadata=metadata, model_name=model, dataset_name=dataset\n",
    "        )[1]\n",
    "    \n",
    "    \n",
    "    display(Markdown(dataset))\n",
    "    df = pd.DataFrame.from_dict(dataset_times, orient=\"index\")\n",
    "    display(df)\n",
    "    dfs[dataset] = (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_overhead(model_times, mean_n2v_time):\n",
    "#     overhead = model_times. / mean_n2v_time\n",
    "\n",
    "#     return overhead\n",
    "\n",
    "overhead_times = {}\n",
    "for ds, ds_df in dfs.items():\n",
    "\n",
    "    mean_n2v_time = ds_df.loc[\"Node2Vec\"][\"computation_time\"][0]\n",
    "    overhead_times[ds] = ds_df.T.apply(\n",
    "        lambda x: x.loc[\"computation_time\"][0] - mean_n2v_time\n",
    "    ).to_dict()\n",
    "    \n",
    "overhead_times_ratio = {}\n",
    "for ds, ds_df in dfs.items():\n",
    "\n",
    "    mean_n2v_time = ds_df.loc[\"Node2Vec\"][\"computation_time\"][0]\n",
    "    overhead_times_ratio[ds] = ds_df.T.apply(\n",
    "        lambda x: x.loc[\"computation_time\"][0] / mean_n2v_time\n",
    "    ).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8273b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(overhead_times_ratio).drop([\"Node2Vec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a902b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "posthoc_times = {}\n",
    "\n",
    "for posthoc in (\"PosthocALL\", \"PosthocEJ\", \"PosthocTB\"):\n",
    "    posthoc_dir = Path(f\"../data/posthoc/{posthoc}/\")\n",
    "    posthoc_metadata_files = [\n",
    "        it for it in list(posthoc_dir.iterdir()) if \"metadata\" in str(it)\n",
    "    ]\n",
    "    metadata = {\n",
    "        path.name.split(\"_\")[0]: pd.read_pickle(path)['metrics']\n",
    "        for path in posthoc_metadata_files\n",
    "    }\n",
    "    \n",
    "    posthoc_calculation_time = {}\n",
    "    for ds, ds_metadata in metadata.items():\n",
    "        snapshot_times = defaultdict(list)\n",
    "        for run in ds_metadata:\n",
    "            snapshot_times = sum([it['calculation_time'] for it in run])\n",
    "        posthoc_calculation_time[ds] = np.mean(snapshot_times)\n",
    "\n",
    "    posthoc_times[posthoc] = posthoc_calculation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(posthoc_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faeb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(overhead_times)\n",
    "df.drop([\"Node2Vec\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df - pd.DataFrame(posthoc_times)['PosthocALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(overhead_times) / pd.DataFrame(posthoc_times)['PosthocALL']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
